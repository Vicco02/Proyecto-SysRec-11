{"cells":[{"cell_type":"markdown","id":"a0ca23dc","metadata":{"id":"a0ca23dc"},"source":["## Random"]},{"cell_type":"markdown","id":"a5c5e162","metadata":{"id":"a5c5e162"},"source":["### Configuración Inicial"]},{"cell_type":"code","source":["!pip uninstall -y numpy\n","!pip install numpy==1.26"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":446},"id":"eoht7K8UUvuL","outputId":"976c5173-a05e-4f6d-f12c-5b5144f3cc44","executionInfo":{"status":"ok","timestamp":1762007000308,"user_tz":180,"elapsed":20859,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}}},"id":"eoht7K8UUvuL","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 2.0.2\n","Uninstalling numpy-2.0.2:\n","  Successfully uninstalled numpy-2.0.2\n","Collecting numpy==1.26\n","  Downloading numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"6d8ff27f26cf43c7a6d88813d440ccdd"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install scikit-surprise --no-build-isolation --no-deps\n","!pip install memory_profiler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8xY-LUmUzjr","outputId":"904de0fd-0879-4100-c72d-f250fb2c286d","executionInfo":{"status":"ok","timestamp":1762007145703,"user_tz":180,"elapsed":89925,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}}},"id":"x8xY-LUmUzjr","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-surprise\n","  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2708551 sha256=aa74f90da1aad64c4bf36db86dadcda0be4209339a67cee214692c1fdb0dfdfb\n","  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise\n","Successfully installed scikit-surprise-1.1.4\n","Collecting memory_profiler\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory_profiler) (5.9.5)\n","Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Installing collected packages: memory_profiler\n","Successfully installed memory_profiler-0.61.0\n"]}]},{"cell_type":"markdown","id":"c3f95148","metadata":{"id":"c3f95148"},"source":["### Instalación de Librerías"]},{"cell_type":"code","execution_count":2,"id":"80bca851","metadata":{"id":"80bca851","executionInfo":{"status":"ok","timestamp":1762007147975,"user_tz":180,"elapsed":2258,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}}},"outputs":[],"source":["import time\n","import json\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict, Counter\n","from memory_profiler import memory_usage\n","import itertools\n","import scipy.sparse as sparse\n","import random\n","import gdown\n","from surprise import SVDpp, Dataset, Reader, accuracy\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"markdown","id":"e0ae5cb5","metadata":{"id":"e0ae5cb5"},"source":["### Importación de los Datos"]},{"cell_type":"code","source":["gdown.download(id='1H_24ycns6zbOVfHFJRI9vGjVffVA5z6v', output='training_ratings.csv', quiet=False)\n","gdown.download(id='1pKmf07ehHOmlvIyT8nv__vPuWE2Z3ygZ', output='validation_ratings.csv', quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"OaUSf9OapGSh","executionInfo":{"status":"ok","timestamp":1762007158895,"user_tz":180,"elapsed":10917,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"0afd5c49-16c0-489e-9e9e-514f55ad2c1d"},"id":"OaUSf9OapGSh","execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1H_24ycns6zbOVfHFJRI9vGjVffVA5z6v\n","From (redirected): https://drive.google.com/uc?id=1H_24ycns6zbOVfHFJRI9vGjVffVA5z6v&confirm=t&uuid=eb3ce19e-27a3-412d-8717-2ea7bc09d203\n","To: /content/training_ratings.csv\n","100%|██████████| 249M/249M [00:03<00:00, 70.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1pKmf07ehHOmlvIyT8nv__vPuWE2Z3ygZ\n","To: /content/validation_ratings.csv\n","100%|██████████| 58.3M/58.3M [00:01<00:00, 51.0MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'validation_ratings.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"id":"8dd256b7","metadata":{"id":"8dd256b7","executionInfo":{"status":"ok","timestamp":1762007165359,"user_tz":180,"elapsed":6461,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}}},"outputs":[],"source":["df_train = pd.read_csv('training_ratings.csv')\n","df_val = pd.read_csv('validation_ratings.csv')"]},{"cell_type":"markdown","id":"62baea42","metadata":{"id":"62baea42"},"source":["### Preprocesamiento de Datos"]},{"cell_type":"code","execution_count":5,"id":"ee022c0b","metadata":{"id":"ee022c0b","executionInfo":{"status":"ok","timestamp":1762007170033,"user_tz":180,"elapsed":4671,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}}},"outputs":[],"source":["df_train.drop_duplicates(inplace=True, subset=['user', 'item'])\n","df_val.drop_duplicates(inplace=True, subset=['user', 'item'])"]},{"cell_type":"code","source":["print(f\"Tamaño original del training set: {len(df_train)}\")\n","\n","# se obtiene un sample debido a que hay muchos datos y se demora mucho\n","df_train_sample = df_train.sample(n=1000000, random_state=42)\n","print(f\"Tamaño del nuevo training set (muestra): {len(df_train_sample)}\")\n","\n","# se obtiene un sample debido a que hay muchos datos y se demora mucho\n","df_val_sample = df_val.sample(n=50000, random_state=42)\n","print(f\"Tamaño del nuevo validation set (muestra): {len(df_val_sample)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT2QRQhMFTZ7","executionInfo":{"status":"ok","timestamp":1762007171297,"user_tz":180,"elapsed":1256,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"898b464b-0e47-4d27-8927-576da28c1127"},"id":"uT2QRQhMFTZ7","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño original del training set: 12390406\n","Tamaño del nuevo training set (muestra): 1000000\n","Tamaño del nuevo validation set (muestra): 50000\n"]}]},{"cell_type":"code","source":["def evaluar_random_topn(df_train, df_val, n=10, sample_per_user=50):\n","    \"\"\"\n","    Genera recomendaciones aleatorias para cada usuario, tomando un sample\n","    limitado de items no vistos para evitar usar toda la matriz.\n","    \"\"\"\n","    # Diccionario {usuario: items que ha visto}\n","    user2seen = df_train.groupby('user')['item'].apply(set).to_dict()\n","\n","    # Lista de todos los items\n","    all_items = df_train['item'].unique().tolist()\n","\n","    top_n = {}\n","    for uid in df_val['user'].unique():\n","        seen = user2seen.get(uid, set())\n","        # Items posibles para recomendar\n","        candidates = list(set(all_items) - seen)\n","        # Tomar un sample limitado\n","        sample_candidates = random.sample(candidates, min(sample_per_user, len(candidates)))\n","        # Tomar n recomendaciones aleatorias\n","        recs = random.sample(sample_candidates, min(n, len(sample_candidates)))\n","        top_n[uid] = [(iid, random.randint(1,5)) for iid in recs]\n","\n","    return top_n\n","\n","\n","# Medir tiempo de ejecución\n","start_time = time.time()\n","top_n = evaluar_random_topn(df_train_sample, df_val_sample, n=10)\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(f\"Tiempo de ejecución: {elapsed_time:.2f} segundos\")\n","\n","# Medir la memoria utilizada\n","memoria = memory_usage(\n","    (evaluar_random_topn, (df_val_sample, df_val_sample), {'n':10})\n",")\n","print(\"Memoria usada (MB):\", max(memoria) - min(memoria))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epNk4GNmBVct","executionInfo":{"status":"ok","timestamp":1762007364867,"user_tz":180,"elapsed":193567,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"e9800447-0b03-4f96-ab5b-f06cf8f30ee3"},"id":"epNk4GNmBVct","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Tiempo de ejecución: 147.73 segundos\n","Memoria usada (MB): 38.1640625\n"]}]},{"cell_type":"code","source":["def rmse_mae_from_topn(top_n, df_val_sample):\n","    real, predicho = [], []\n","    total = sum(len(recs) for recs in top_n.values())\n","    i = 0\n","    for uid, recs in top_n.items():\n","      for iid, pred in recs:\n","        real_vals = df_val_sample.loc[(df_val_sample['user'] == uid) & (df_val_sample['item'] == iid), 'rating']\n","        if not real_vals.empty:\n","            real.append(real_vals.values[0])\n","            predicho.append(pred)\n","        i += 1\n","        if i % 10000 == 0 or i == total:  # muestra cada 100 pasos o al final\n","            progreso = (i / total) * 100\n","            print(f\"Progreso: {i}/{total} ({progreso:.2f}%)\")\n","\n","    return math.sqrt(mean_squared_error(real, predicho)), mean_absolute_error(real, predicho)\n","\n","rmse, mae = rmse_mae_from_topn(top_n, df_val_sample)\n","print(\"RMSE para las top n recomendaciones\", rmse)\n","print(\"MAE para las top n recomendaciones\", mae)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQptPHUXIuPi","executionInfo":{"status":"ok","timestamp":1762010827775,"user_tz":180,"elapsed":3462933,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"c3c3f2b8-0b4b-4aea-d550-681fdef839a5"},"id":"sQptPHUXIuPi","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Progreso: 10000/374620 (2.67%)\n","Progreso: 20000/374620 (5.34%)\n","Progreso: 30000/374620 (8.01%)\n","Progreso: 40000/374620 (10.68%)\n","Progreso: 50000/374620 (13.35%)\n","Progreso: 60000/374620 (16.02%)\n","Progreso: 70000/374620 (18.69%)\n","Progreso: 80000/374620 (21.35%)\n","Progreso: 90000/374620 (24.02%)\n","Progreso: 100000/374620 (26.69%)\n","Progreso: 110000/374620 (29.36%)\n","Progreso: 120000/374620 (32.03%)\n","Progreso: 130000/374620 (34.70%)\n","Progreso: 140000/374620 (37.37%)\n","Progreso: 150000/374620 (40.04%)\n","Progreso: 160000/374620 (42.71%)\n","Progreso: 170000/374620 (45.38%)\n","Progreso: 180000/374620 (48.05%)\n","Progreso: 190000/374620 (50.72%)\n","Progreso: 200000/374620 (53.39%)\n","Progreso: 210000/374620 (56.06%)\n","Progreso: 220000/374620 (58.73%)\n","Progreso: 230000/374620 (61.40%)\n","Progreso: 240000/374620 (64.06%)\n","Progreso: 250000/374620 (66.73%)\n","Progreso: 260000/374620 (69.40%)\n","Progreso: 270000/374620 (72.07%)\n","Progreso: 280000/374620 (74.74%)\n","Progreso: 290000/374620 (77.41%)\n","Progreso: 300000/374620 (80.08%)\n","Progreso: 310000/374620 (82.75%)\n","Progreso: 320000/374620 (85.42%)\n","Progreso: 330000/374620 (88.09%)\n","Progreso: 340000/374620 (90.76%)\n","Progreso: 350000/374620 (93.43%)\n","Progreso: 360000/374620 (96.10%)\n","Progreso: 370000/374620 (98.77%)\n","Progreso: 374620/374620 (100.00%)\n","RMSE para las top n recomendaciones 4.680122689320951\n","MAE para las top n recomendaciones 4.325806451612903\n"]}]},{"cell_type":"markdown","source":["Ahora haremos lo mismo pero para un grupo de 4 personas que han calificado ese item (haremos 4 personas por mas que haya juegos que es de máximo 2 o 10 etc por simplicidad). Lo que hacemos es calcular el promedio real de las calificaciones de esas 4 personas y compararlo contra una predicción grupal generada de manera completamente aleatoria en el rango de ratings posibles."],"metadata":{"id":"U7hu4Q0nG96z"},"id":"U7hu4Q0nG96z"},{"cell_type":"code","source":["def evaluar_random_topn_grupos(df_train, df_val, n=10, sample_per_user=50):\n","    \"\"\"\n","    Genera recomendaciones aleatorias para cada usuario, tomando un sample\n","    limitado de items no vistos para evitar usar toda la matriz.\n","    \"\"\"\n","    # Diccionario {usuario: items que ha visto}\n","    user2seen = df_train.groupby('user')['item'].apply(set).to_dict()\n","\n","    # Lista de todos los items\n","    all_items = df_train['item'].unique().tolist()\n","\n","    top_n = {}\n","    # armar grupos\n","    usuarios = df_val['user'].unique()\n","    grupos = [usuarios[i:i+4] for i in range(0, len(usuarios) - len(usuarios)%4, 4)]\n","\n","    seen_group = set()\n","    for grupo in grupos:\n","      for u in grupo:\n","          seen_group |= user2seen.get(u, set())\n","          # Items posibles para recomendar\n","          candidates = list(set(all_items) - seen_group)\n","          # Tomar un sample limitado\n","          sample_candidates = random.sample(candidates, min(sample_per_user, len(candidates)))\n","          # Tomar n recomendaciones aleatorias\n","          recs = random.sample(sample_candidates, min(n, len(sample_candidates)))\n","          top_n[tuple(grupo)] = [(iid, random.randint(1,5)) for iid in recs]\n","\n","    return top_n\n","\n","\n","# Medir tiempo de ejecución\n","start_time = time.time()\n","top_n_grupo = evaluar_random_topn_grupos(df_train_sample, df_val_sample, n=10)\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print(f\"Tiempo de ejecución: {elapsed_time:.2f} segundos\")\n","\n","# Medir la memoria utilizada\n","memoria = memory_usage(\n","    (evaluar_random_topn_grupos, (df_train_sample, df_val_sample), {'n':10})\n",")\n","print(\"Memoria usada (MB):\", max(memoria) - min(memoria))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epkNsTyrKxkT","executionInfo":{"status":"ok","timestamp":1762011229866,"user_tz":180,"elapsed":402102,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"6faf1557-09a9-4968-fcaf-653af644797f"},"id":"epkNsTyrKxkT","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Tiempo de ejecución: 198.39 segundos\n","Memoria usada (MB): 106.5390625\n"]}]},{"cell_type":"code","source":["def rmse_mae_from_topn_grupo(top_n_grupo, df_val_sample):\n","    real, predicho = [], []\n","    total = sum(len(recs) for recs in top_n.values())\n","    i = 0\n","    for grupo, recs in top_n_grupo.items():\n","      for iid, pred in recs:\n","        real_vals = df_val_sample.loc[(df_val_sample['user'].isin(grupo)) & (df_val_sample['item'] == iid), 'rating']\n","        if not real_vals.empty:\n","            real.append(real_vals.values[0])\n","            predicho.append(pred)\n","        i += 1\n","        if i % 10000 == 0 or i == total:  # muestra cada 100 pasos o al final\n","            progreso = (i / total) * 100\n","            print(f\"Progreso: {i}/{total} ({progreso:.2f}%)\")\n","\n","    return math.sqrt(mean_squared_error(real, predicho)), mean_absolute_error(real, predicho)\n","\n","rmse_grupo, mae_grupo = rmse_mae_from_topn_grupo(top_n_grupo, df_val_sample)\n","print(\"RMSE para las top n recomendaciones\", rmse_grupo)\n","print(\"MAE para las top n recomendaciones\", mae_grupo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qc24swLLJkoV","executionInfo":{"status":"ok","timestamp":1762011888539,"user_tz":180,"elapsed":658669,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"b0cbe1ec-2ea3-4a2a-c0f7-549a0144367d"},"id":"qc24swLLJkoV","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Progreso: 10000/374620 (2.67%)\n","Progreso: 20000/374620 (5.34%)\n","Progreso: 30000/374620 (8.01%)\n","Progreso: 40000/374620 (10.68%)\n","Progreso: 50000/374620 (13.35%)\n","Progreso: 60000/374620 (16.02%)\n","Progreso: 70000/374620 (18.69%)\n","Progreso: 80000/374620 (21.35%)\n","Progreso: 90000/374620 (24.02%)\n","RMSE para las top n recomendaciones 4.415880433163924\n","MAE para las top n recomendaciones 4.0\n"]}]},{"cell_type":"markdown","source":["Los códigos para random se adaptaron de un codigo inicial creado, la adaptación de este código se encuentra aquí: https://chatgpt.com/share/68e00c31-dbf8-8006-bacd-84f0296d467c\n"],"metadata":{"id":"1Wz3zHqTJ2pV"},"id":"1Wz3zHqTJ2pV"},{"cell_type":"code","source":["from sklearn.metrics import ndcg_score\n","\n","print(\"Creando DataFrame de evaluación aleatorio...\")\n","\n","df_eval = df_val_sample.copy()\n","\n","df_eval = df_eval.rename(columns={'user': 'userID', 'item': 'itemID'})\n","\n","df_eval['label'] = (df_eval['rating'] >= 7).astype(int)\n","np.random.seed(42)\n","df_eval['score'] = np.random.rand(len(df_eval))\n","\n","print(\"DataFrame de evaluación (Random) creado con éxito.\")\n","print(df_eval.head())\n","\n","print(\"\\nCreando grupos sintéticos...\")\n","user_counts = df_eval['userID'].value_counts()\n","valid_users = user_counts[user_counts >= 10].index.tolist()\n","\n","np.random.seed(42)\n","num_groups = 1000\n","group_size = 4\n","groups = [np.random.choice(valid_users, group_size, replace=False) for _ in range(num_groups)]\n","\n","print(f\"Se crearon {len(groups)} grupos sintéticos de tamaño {group_size}.\")\n","print(\"Ejemplo de un grupo:\", groups[0])\n","\n","print(\"\\nAgregando predicciones para cada grupo...\")\n","all_group_recs = []\n","\n","for group_id, user_ids in enumerate(groups):\n","    group_predictions = df_eval[df_eval['userID'].isin(user_ids)]\n","\n","    item_scores_per_group = group_predictions.groupby('itemID').agg(\n","        avg_score=('score', 'mean'),\n","        min_score=('score', 'min'),\n","        max_score=('score', 'max'),\n","\n","        group_label=('label', lambda x: 1 if all(x == 1) else 0)\n","    ).reset_index()\n","\n","    item_scores_per_group['group_id'] = group_id\n","    all_group_recs.append(item_scores_per_group)\n","\n","df_group_eval = pd.concat(all_group_recs, ignore_index=True)\n","print(\"Agregación completada.\")\n","print(df_group_eval.head())\n","\n","\n","def precision_recall_at_k(group, k):\n","    \"\"\"Calcula Precision@K y Recall@K para un solo grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk = group.head(k)\n","    hits = topk['label'].sum()\n","    total_relevant = group['label'].sum()\n","    precision = hits / k if k > 0 else 0\n","    recall = hits / total_relevant if total_relevant > 0 else 0\n","    return precision, recall\n","\n","def ndcg_at_k(group, k):\n","    \"\"\"Calcula nDCG@K para un solo grupo.\"\"\"\n","    if group['label'].sum() == 0:\n","        return 0.0\n","    ranked_group = group.sort_values('score', ascending=False).head(k)\n","    if len(ranked_group) < 2:\n","        return 0.0\n","    true_relevance = np.asarray([ranked_group['label'].values])\n","    predicted_scores = np.asarray([ranked_group['score'].values])\n","    return ndcg_score(true_relevance, predicted_scores)\n","\n","strategies = {\n","    'Average': 'avg_score',\n","    'Least Misery': 'min_score',\n","    'Most Pleasure': 'max_score'\n","}\n","\n","group_results = []\n","K_values = [10]\n","\n","for strategy_name, score_column in strategies.items():\n","    print(f\"\\nEvaluando estrategia (Random): {strategy_name}...\")\n","    df_strategy_eval = df_group_eval[['group_id', 'itemID', 'group_label']].copy()\n","    df_strategy_eval.rename(columns={'group_label': 'label'}, inplace=True)\n","    df_strategy_eval['score'] = df_group_eval[score_column]\n","\n","    grouped_strategy = df_strategy_eval.groupby('group_id')\n","\n","    for k in K_values:\n","        metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","        avg_precision = np.mean([m[0] for m in metrics])\n","        avg_recall = np.mean([m[1] for m in metrics])\n","        ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n","        avg_ndcg = np.mean(ndcg_scores)\n","        group_results.append({\n","            'Model': 'Random',\n","            'Strategy': strategy_name,\n","            'K': k,\n","            'Precision@K': avg_precision,\n","            'Recall@K': avg_recall,\n","            'nDCG@K': avg_ndcg\n","        })\n","\n","group_results_df = pd.DataFrame(group_results)\n","\n","print(\"\\n--- Resultados de Evaluación Grupal para Random ---\")\n","print(group_results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nHeuu_oyCcC","executionInfo":{"status":"ok","timestamp":1762011911276,"user_tz":180,"elapsed":22734,"user":{"displayName":"VICENTE CORREA","userId":"10986709379509559146"}},"outputId":"1686ff04-ab16-47a6-9a2f-ba6360735ea1"},"id":"0nHeuu_oyCcC","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Creando DataFrame de evaluación aleatorio...\n","DataFrame de evaluación (Random) creado con éxito.\n","         itemID  rating       userID  label     score\n","1549328  162886     7.0    bigbarazi      1  0.374540\n","1832787  155987    10.0        espoo      1  0.950714\n","1118582  156858     7.0   Scooperman      1  0.731994\n","788525     1899    10.0   ManiacRafa      1  0.598658\n","513706   156714     7.5  Hamez Davez      1  0.156019\n","\n","Creando grupos sintéticos...\n","Se crearon 1000 grupos sintéticos de tamaño 4.\n","Ejemplo de un grupo: ['punkin312' 'Posco' 'leffe dubbel' 'MindSwap']\n","\n","Agregando predicciones para cada grupo...\n","Agregación completada.\n","   itemID  avg_score  min_score  max_score  group_label  group_id\n","0      13   0.080063   0.080063   0.080063            1         0\n","1     655   0.872806   0.872806   0.872806            0         0\n","2    1144   0.273319   0.273319   0.273319            0         0\n","3    1829   0.404969   0.404969   0.404969            0         0\n","4    2569   0.005570   0.005570   0.005570            0         0\n","\n","Evaluando estrategia (Random): Average...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1952114365.py:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-1952114365.py:92: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia (Random): Least Misery...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1952114365.py:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-1952114365.py:92: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia (Random): Most Pleasure...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1952114365.py:89: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Resultados de Evaluación Grupal para Random ---\n","    Model       Strategy   K  Precision@K  Recall@K    nDCG@K\n","0  Random        Average  10       0.4644  0.187787  0.734357\n","1  Random   Least Misery  10       0.4641  0.187695  0.734323\n","2  Random  Most Pleasure  10       0.4641  0.187562  0.730359\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1952114365.py:92: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}
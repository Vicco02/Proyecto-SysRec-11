{"cells":[{"cell_type":"markdown","id":"a5c5e162","metadata":{"id":"a5c5e162"},"source":["### Configuración Inicial"]},{"cell_type":"code","execution_count":1,"id":"1MPlDVmKIpyn","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":17159,"status":"ok","timestamp":1764995582856,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"1MPlDVmKIpyn","outputId":"c39dafc7-8647-4fcc-b03b-aa771ffd7852"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 1.26.0\n","Uninstalling numpy-1.26.0:\n","  Successfully uninstalled numpy-1.26.0\n","Collecting numpy==1.26\n","  Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n","Installing collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","music21 9.9.1 requires numpy>=1.26.4, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"2d5a00da46a745a7b591c237b5a6c7c7"}},"metadata":{}}],"source":["!pip uninstall -y numpy\n","!pip install numpy==1.26"]},{"cell_type":"code","execution_count":2,"id":"QZtuU35LAwh4","metadata":{"executionInfo":{"elapsed":83766,"status":"ok","timestamp":1764995666653,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"QZtuU35LAwh4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba26751f-ca38-4f12-dc36-b5e68a9d2824"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-surprise\n","  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2708558 sha256=e44fa3913df5b81e3b7f6c3d5e4c9f61a565f551d4318f3adc17467d8468ce09\n","  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise\n","Successfully installed scikit-surprise-1.1.4\n","Collecting memory_profiler\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory_profiler) (5.9.5)\n","Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Installing collected packages: memory_profiler\n","Successfully installed memory_profiler-0.61.0\n"]}],"source":["!pip install scikit-surprise --no-build-isolation --no-deps\n","!pip install memory_profiler"]},{"cell_type":"markdown","id":"c3f95148","metadata":{"id":"c3f95148"},"source":["### Instalación de Librerías"]},{"cell_type":"code","execution_count":3,"id":"80bca851","metadata":{"executionInfo":{"elapsed":1167,"status":"ok","timestamp":1764995667836,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"80bca851"},"outputs":[],"source":["import pandas as pd\n","import gdown\n","from surprise import Dataset, Reader, SVDpp, accuracy\n","from surprise.model_selection import train_test_split\n","import time\n","from memory_profiler import memory_usage\n","from collections import defaultdict"]},{"cell_type":"markdown","id":"e0ae5cb5","metadata":{"id":"e0ae5cb5"},"source":["### Importación de los Datos"]},{"cell_type":"code","execution_count":4,"id":"8dd256b7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16924,"status":"ok","timestamp":1764995684766,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"8dd256b7","outputId":"ba19da2e-deca-4ec3-9fa1-667e40464f73"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx\n","From (redirected): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx&confirm=t&uuid=f3c8339b-d0b0-4ef9-a460-68585e9aeb05\n","To: /content/training_ratings.csv\n","100%|██████████| 205M/205M [00:02<00:00, 102MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16\n","To: /content/validation_ratings.csv\n","100%|██████████| 64.4M/64.4M [00:00<00:00, 95.8MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO\n","To: /content/mechanics.csv\n","100%|██████████| 7.05M/7.05M [00:00<00:00, 45.5MB/s]\n"]}],"source":["gdown.download(id='1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx', output='training_ratings.csv', quiet=False)\n","gdown.download(id='1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16', output='validation_ratings.csv', quiet=False)\n","\n","# dataset mechanics\n","gdown.download(id='1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO', output='mechanics.csv', quiet=False)\n","df_mechanics = pd.read_csv('mechanics.csv')\n","\n","df_train = pd.read_csv('training_ratings.csv')\n","df_val = pd.read_csv('validation_ratings.csv')"]},{"cell_type":"markdown","id":"62baea42","metadata":{"id":"62baea42"},"source":["### Preprocesamiento de Datos"]},{"cell_type":"code","execution_count":5,"id":"ee022c0b","metadata":{"id":"ee022c0b","executionInfo":{"status":"ok","timestamp":1764995688455,"user_tz":180,"elapsed":3678,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[],"source":["df_train.drop_duplicates(inplace=True, subset=['user', 'item'])\n","df_val.drop_duplicates(inplace=True, subset=['user', 'item'])"]},{"cell_type":"code","execution_count":6,"id":"8n9XS5pSh4dm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1094,"status":"ok","timestamp":1764995689556,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"8n9XS5pSh4dm","outputId":"a348328c-ce58-4ea9-886c-0aa7340eded0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño original del training set: 10200445\n","Tamaño del nuevo training set (muestra): 1000000\n"]}],"source":["print(f\"Tamaño original del training set: {len(df_train)}\")\n","\n","# se obtiene un sample debido a que hay muchos datos y se demora mucho\n","df_train_sample = df_train.sample(n=1000000, random_state=42)\n","print(f\"Tamaño del nuevo training set (muestra): {len(df_train_sample)}\")\n"]},{"cell_type":"code","source":["df_mechanics.set_index('BGGId', inplace=True)\n","print(\"Datos de mecánicas cargados y listos.\")\n","\n","# --- Calcular la popularidad de los ítems ---\n","item_popularity = df_train['item'].value_counts().to_dict()\n","total_interactions = len(df_train)\n","\n","# Convertimos las cuentas en probabilidades para el cálculo de novedad\n","item_popularity_prob = {item_id: count / total_interactions for item_id, count in item_popularity.items()}\n","print(f\"Popularidad calculada para {len(item_popularity)} ítems.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7QpXnfck0i2","executionInfo":{"status":"ok","timestamp":1764995689957,"user_tz":180,"elapsed":397,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"7382991e-eaa9-4b18-c484-31528c53e370"},"id":"q7QpXnfck0i2","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Datos de mecánicas cargados y listos.\n","Popularidad calculada para 16748 ítems.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","def novelty_at_k(group, k, popularity_prob):\n","    \"\"\"Calcula la Novedad@K para un solo usuario/grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk_items = group.head(k)['itemID']\n","\n","    novelty_scores = []\n","    for item_id in topk_items:\n","        # Usar una probabilidad pequeña si el ítem no se vio en el entrenamiento\n","        prob = popularity_prob.get(item_id, 1e-6)\n","        novelty_scores.append(-np.log2(prob))\n","\n","    return np.mean(novelty_scores) if novelty_scores else 0.0\n","\n","def diversity_at_k(group, k, mechanics_df):\n","    \"\"\"Calcula la Diversidad@K (Intra-List Diversity) para un solo usuario/grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk_items = group.head(k)['itemID'].tolist()\n","\n","    # Filtra ítems para asegurar que existan en el dataframe de mecánicas\n","    topk_items = [item for item in topk_items if item in mechanics_df.index]\n","\n","    if len(topk_items) < 2:\n","        return 0.0\n","\n","    # Obtiene los vectores de mecánicas para los ítems recomendados\n","    item_vectors = mechanics_df.loc[topk_items].values\n","\n","    # Calcula la disimilitud del coseno (1 - similitud)\n","    dissimilarity_sum = 0\n","    num_pairs = 0\n","    for i in range(len(item_vectors)):\n","        for j in range(i + 1, len(item_vectors)):\n","            sim = cosine_similarity([item_vectors[i]], [item_vectors[j]])[0][0]\n","            dissimilarity_sum += (1 - sim)\n","            num_pairs += 1\n","\n","    return dissimilarity_sum / num_pairs if num_pairs > 0 else 0.0"],"metadata":{"id":"PGrm2p4wljmS","executionInfo":{"status":"ok","timestamp":1764995691330,"user_tz":180,"elapsed":1361,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"id":"PGrm2p4wljmS","execution_count":8,"outputs":[]},{"cell_type":"markdown","id":"71ZdaPJVIxIH","metadata":{"id":"71ZdaPJVIxIH"},"source":["### Configuración de Experimentos"]},{"cell_type":"code","execution_count":9,"id":"85TINbrjIlTf","metadata":{"id":"85TINbrjIlTf","executionInfo":{"status":"ok","timestamp":1764995699544,"user_tz":180,"elapsed":8205,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[],"source":["reader = Reader(rating_scale=(0, 10))\n","train_data = Dataset.load_from_df(df_train_sample[['user', 'item', 'rating']], reader)\n","trainset = train_data.build_full_trainset()\n","\n","validation_tuples = [tuple(x) for x in df_val[['user', 'item', 'rating']].to_numpy()]"]},{"cell_type":"markdown","id":"xN0wDRY5Kg1F","metadata":{"id":"xN0wDRY5Kg1F"},"source":["### Predicción de ratings y top N\n","\n"]},{"cell_type":"code","execution_count":10,"id":"33196b23","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33196b23","outputId":"896e8ae7-617d-484f-9ce8-200307a8c282","executionInfo":{"status":"ok","timestamp":1764996102574,"user_tz":180,"elapsed":403023,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[" processing epoch 0\n"," processing epoch 1\n"," processing epoch 2\n"," processing epoch 3\n"," processing epoch 4\n"," processing epoch 5\n"," processing epoch 6\n"," processing epoch 7\n"," processing epoch 8\n"," processing epoch 9\n"," processing epoch 10\n"," processing epoch 11\n"," processing epoch 12\n"," processing epoch 13\n"," processing epoch 14\n"," processing epoch 15\n"," processing epoch 16\n"," processing epoch 17\n"," processing epoch 18\n"," processing epoch 19\n","RMSE: 1.3031\n","MAE:  0.9908\n","RMSE: 1.3032\n","MAE:  0.9911\n","\n","--- Resumen de Rendimiento (SVD++) ---\n","RMSE final: 1.3031\n","MAE final: 0.9908\n","Tiempo de ejecución: 201.93 segundos\n","Memoria utilizada: 1506.14 MB\n"]}],"source":["def evaluar_svdpp(trainset, testset, n_factors, n_epochs, lr_all, reg_all, verbose):\n","    \"\"\"\n","    Entrena, predice y evalúa el modelo SVD++, retornando el RMSE y MAE.\n","    \"\"\"\n","    algo = SVDpp(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all, verbose=verbose)\n","\n","    algo.fit(trainset)\n","\n","    predictions = algo.test(testset)\n","\n","    rmse = accuracy.rmse(predictions)\n","    mae = accuracy.mae(predictions)\n","\n","    return rmse, mae, predictions\n","\n","start_time = time.time()\n","\n","rmse_resultado, mae_resultado, predictions = evaluar_svdpp(trainset, validation_tuples, 50, 20, 0.01, 0.02, True)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","\n","memoria_usada = memory_usage((evaluar_svdpp, (trainset, validation_tuples, 50, 20, 0.01, 0.02, False)))\n","memoria_max = max(memoria_usada) - min(memoria_usada)\n","\n","print(f\"\\n--- Resumen de Rendimiento (SVD++) ---\")\n","print(f\"RMSE final: {rmse_resultado:.4f}\")\n","print(f\"MAE final: {mae_resultado:.4f}\")\n","print(f\"Tiempo de ejecución: {elapsed_time:.2f} segundos\")\n","print(f\"Memoria utilizada: {memoria_max:.2f} MB\")"]},{"cell_type":"code","execution_count":11,"id":"CxphCc0IRWJG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxphCc0IRWJG","outputId":"a125b70f-97bc-4671-d258-848feb6fda8f","executionInfo":{"status":"ok","timestamp":1764996104991,"user_tz":180,"elapsed":2408,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Top 10 predicciones para el usuario ' beastvol':\n","  Ítem ID: 3076, Rating Predicho: 7.56\n"]}],"source":["def get_top_n(predictions, n=10):\n","    \"\"\"Devuelve las N-mejores recomendaciones para cada usuario.\"\"\"\n","    top_n = defaultdict(list)\n","    for uid, iid, true_r, est, _ in predictions:\n","        top_n[uid].append((iid, est))\n","\n","    for uid, user_ratings in top_n.items():\n","        user_ratings.sort(key=lambda x: x[1], reverse=True)\n","        top_n[uid] = user_ratings[:n]\n","\n","    return top_n\n","\n","top_n_predictions = get_top_n(predictions, n=10)\n","\n","user_id_ejemplo = df_val['user'].iloc[0]\n","if user_id_ejemplo in top_n_predictions:\n","    print(f\"\\nTop 10 predicciones para el usuario '{user_id_ejemplo}':\")\n","    for iid, est_rating in top_n_predictions[user_id_ejemplo]:\n","        print(f\"  Ítem ID: {iid}, Rating Predicho: {est_rating:.2f}\")"]},{"cell_type":"markdown","id":"mfZ7iTOzUMBu","metadata":{"id":"mfZ7iTOzUMBu"},"source":["Grupales:"]},{"cell_type":"code","execution_count":12,"id":"LlpPlLc14x8m","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168699,"status":"ok","timestamp":1764996273694,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"},"user_tz":180},"id":"LlpPlLc14x8m","outputId":"10fa844c-3079-4fad-de07-239c19f14a41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Convirtiendo predicciones de Surprise a DataFrame...\n","DataFrame de evaluación creado con éxito.\n","      userID  itemID  label     score\n","0   beastvol    3076      1  7.562782\n","1    mycroft    3284      0  7.679667\n","2    mycroft    5336      1  7.487979\n","3   -=Yod@=-  264295      1  7.056427\n","4   -=Yod@=-  167791      1  7.101579\n","\n","Creando grupos sintéticos...\n","Se crearon 1000 grupos sintéticos de tamaño 4.\n","Ejemplo de un grupo: ['dojhar' 'Xellir' 'Novastinger' 'jasshill']\n","\n","Agregando predicciones para cada grupo...\n","Agregación completada.\n","   itemID  avg_score  min_score  max_score  group_label  group_id\n","0       5   7.111313   7.111313   7.111313            1         0\n","1     112   7.192929   7.192929   7.192929            1         0\n","2     199   6.101544   6.101544   6.101544            0         0\n","3     220   6.692581   6.692581   6.692581            0         0\n","4     256   6.280980   6.280980   6.280980            0         0\n","\n","Evaluando estrategia: Average...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-424754598.py:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-424754598.py:99: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia: Least Misery...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-424754598.py:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-424754598.py:99: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia: Most Pleasure...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-424754598.py:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Resultados de Evaluación Grupal para SVD++ ---\n","        Strategy   K  Precision@K  Recall@K    nDCG@K\n","0        Average  10       0.9022  0.143456  0.965680\n","1   Least Misery  10       0.9007  0.143193  0.965407\n","2  Most Pleasure  10       0.9090  0.144599  0.967759\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-424754598.py:99: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n"]}],"source":["import numpy as np\n","from sklearn.metrics import ndcg_score\n","\n","print(\"Convirtiendo predicciones de Surprise a DataFrame...\")\n","preds_df = pd.DataFrame(predictions, columns=['userID', 'itemID', 'rating', 'score', 'details'])\n","\n","# Un rating >= 7 se considera una interacción positiva (relevante).\n","preds_df['label'] = (preds_df['rating'] >= 7).astype(int)\n","\n","df_eval = preds_df[['userID', 'itemID', 'label', 'score']]\n","print(\"DataFrame de evaluación creado con éxito.\")\n","print(df_eval.head())\n","\n","\n","\n","print(\"\\nCreando grupos sintéticos...\")\n","user_counts = df_eval['userID'].value_counts()\n","# Nos quedamos con usuarios que tienen al menos 10 ratings para formar grupos más consistentes\n","valid_users = user_counts[user_counts >= 10].index.tolist()\n","\n","np.random.seed(42)\n","num_groups = 1000\n","group_size = 4\n","groups = [np.random.choice(valid_users, group_size, replace=False) for _ in range(num_groups)]\n","\n","print(f\"Se crearon {len(groups)} grupos sintéticos de tamaño {group_size}.\")\n","print(\"Ejemplo de un grupo:\", groups[0])\n","\n","\n","# --- PASO 3: Agregar Predicciones para cada Grupo ---\n","\n","print(\"\\nAgregando predicciones para cada grupo...\")\n","all_group_recs = []\n","\n","for group_id, user_ids in enumerate(groups):\n","    group_predictions = df_eval[df_eval['userID'].isin(user_ids)]\n","\n","    item_scores_per_group = group_predictions.groupby('itemID').agg(\n","        # Estrategias de agregación\n","        avg_score=('score', 'mean'),\n","        min_score=('score', 'min'),\n","        max_score=('score', 'max'),\n","\n","        # Ground Truth del grupo: Un ítem es relevante si AL MENOS UN miembro le dio un rating positivo.\n","        group_label=('label', lambda x: 1 if x.sum() > 0 else 0)\n","    ).reset_index()\n","\n","    item_scores_per_group['group_id'] = group_id\n","    all_group_recs.append(item_scores_per_group)\n","\n","df_group_eval = pd.concat(all_group_recs, ignore_index=True)\n","print(\"Agregación completada.\")\n","print(df_group_eval.head())\n","\n","\n","# --- PASO 4: Funciones de Métrica y Evaluación Final ---\n","\n","def precision_recall_at_k(group, k):\n","    \"\"\"Calcula Precision@K y Recall@K para un solo grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk = group.head(k)\n","    hits = topk['label'].sum()\n","    total_relevant = group['label'].sum()\n","    precision = hits / k if k > 0 else 0\n","    recall = hits / total_relevant if total_relevant > 0 else 0\n","    return precision, recall\n","\n","def ndcg_at_k(group, k):\n","    \"\"\"Calcula nDCG@K para un solo grupo.\"\"\"\n","    if group['label'].sum() == 0:\n","        return 0.0\n","    ranked_group = group.sort_values('score', ascending=False).head(k)\n","    if len(ranked_group) < 2:\n","        return 0.0\n","    true_relevance = np.asarray([ranked_group['label'].values])\n","    predicted_scores = np.asarray([ranked_group['score'].values])\n","    return ndcg_score(true_relevance, predicted_scores)\n","\n","strategies = {\n","    'Average': 'avg_score',\n","    'Least Misery': 'min_score',\n","    'Most Pleasure': 'max_score'\n","}\n","\n","group_results = []\n","K_values = [10]\n","for strategy_name, score_column in strategies.items():\n","    print(f\"\\nEvaluando estrategia: {strategy_name}...\")\n","    df_strategy_eval = df_group_eval[['group_id', 'itemID', 'group_label']].copy()\n","    df_strategy_eval.rename(columns={'group_label': 'label'}, inplace=True)\n","    df_strategy_eval['score'] = df_group_eval[score_column]\n","\n","    grouped_strategy = df_strategy_eval.groupby('group_id')\n","\n","    for k in K_values:\n","        metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","        avg_precision = np.mean([m[0] for m in metrics])\n","        avg_recall = np.mean([m[1] for m in metrics])\n","        ndcg_scores = grouped_strategy.apply(lambda x: ndcg_at_k(x, k))\n","        avg_ndcg = np.mean(ndcg_scores)\n","        group_results.append({\n","            'Strategy': strategy_name,\n","            'K': k,\n","            'Precision@K': avg_precision,\n","            'Recall@K': avg_recall,\n","            'nDCG@K': avg_ndcg\n","        })\n","\n","group_results_df = pd.DataFrame(group_results)\n","\n","print(\"\\n--- Resultados de Evaluación Grupal para SVD++ ---\")\n","print(group_results_df)"]},{"cell_type":"markdown","id":"V4cnXdABT95i","metadata":{"id":"V4cnXdABT95i"},"source":["Individuales:"]},{"cell_type":"code","execution_count":13,"id":"paI12-UKT_fH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"paI12-UKT_fH","outputId":"a59ba717-6d38-4478-c393-d9e6ca5385e0","executionInfo":{"status":"ok","timestamp":1765000138918,"user_tz":180,"elapsed":1137684,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Calculando métricas individuales para SVD++...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-3113136939.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_users.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-3113136939.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_users.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-3113136939.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_users.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Resultados de Evaluación Individual para SVD++ ---\n","    K  Precision@K  Recall@K    nDCG@K  Novelty@K  Diversity@K\n","0  10     0.468084  0.835879  0.829852  10.715596      0.74006\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3113136939.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_users.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]}],"source":["from sklearn.metrics import ndcg_score\n","import numpy as np\n","\n","preds_df = pd.DataFrame(predictions, columns=['userID', 'itemID', 'rating', 'score', 'details'])\n","preds_df['label'] = (preds_df['rating'] >= 7).astype(int)\n","df_eval = preds_df[['userID', 'itemID', 'label', 'score']]\n","\n","# --- Funciones de métrica (las mismas de tu sección grupal) ---\n","def precision_recall_at_k(group, k):\n","    group = group.sort_values('score', ascending=False)\n","    topk = group.head(k)\n","    hits = topk['label'].sum()\n","    total_relevant = group['label'].sum()\n","    precision = hits / k if k > 0 else 0\n","    recall = hits / total_relevant if total_relevant > 0 else 0\n","    return precision, recall\n","\n","def ndcg_at_k(group, k):\n","    if group['label'].sum() == 0: return 0.0\n","    ranked_group = group.sort_values('score', ascending=False).head(k)\n","    # nDCG requiere al menos 2 ítems para ser calculado\n","    if len(ranked_group) < 2: return 0.0\n","    true_relevance = np.asarray([ranked_group['label'].values])\n","    predicted_scores = np.asarray([ranked_group['score'].values])\n","    return ndcg_score(true_relevance, predicted_scores)\n","\n","# --- Evaluación ---\n","K_values = [10]\n","individual_results = []\n","print(\"Calculando métricas individuales para SVD++...\")\n","\n","grouped_users = df_eval.groupby('userID')\n","\n","for k in K_values:\n","    # Métricas de precisión y ranking\n","    metrics = grouped_users.apply(lambda x: precision_recall_at_k(x, k))\n","    avg_precision = np.mean([m[0] for m in metrics])\n","    avg_recall = np.mean([m[1] for m in metrics])\n","    avg_ndcg = grouped_users.apply(lambda x: ndcg_at_k(x, k)).mean()\n","\n","    # Nuevas métricas de Novedad y Diversidad\n","    avg_novelty = grouped_users.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","    avg_diversity = grouped_users.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n","\n","    individual_results.append({\n","        'K': k,\n","        'Precision@K': avg_precision,\n","        'Recall@K': avg_recall,\n","        'nDCG@K': avg_ndcg,\n","        'Novelty@K': avg_novelty,\n","        'Diversity@K': avg_diversity\n","    })\n","\n","individual_results_df = pd.DataFrame(individual_results)\n","print(\"\\n--- Resultados de Evaluación Individual para SVD++ ---\")\n","print(individual_results_df)"]},{"cell_type":"markdown","source":["Grupales"],"metadata":{"id":"0ZQ4XG5nmP6S"},"id":"0ZQ4XG5nmP6S"},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import ndcg_score\n","\n","# --- PASO 1: Crear DataFrame de Evaluación ---\n","print(\"Convirtiendo predicciones de Surprise a DataFrame...\")\n","preds_df = pd.DataFrame(predictions, columns=['userID', 'itemID', 'rating', 'score', 'details'])\n","preds_df['label'] = (preds_df['rating'] >= 7).astype(int)\n","df_eval = preds_df[['userID', 'itemID', 'label', 'score']]\n","print(\"DataFrame de evaluación creado con éxito.\")\n","\n","# --- PASO 2: Crear Grupos Sintéticos ---\n","print(\"\\nCreando grupos sintéticos...\")\n","user_counts = df_eval['userID'].value_counts()\n","valid_users = user_counts[user_counts >= 10].index.tolist()\n","np.random.seed(42)\n","num_groups = 1000\n","group_size = 4\n","groups = [np.random.choice(valid_users, group_size, replace=False) for _ in range(num_groups)]\n","print(f\"Se crearon {len(groups)} grupos sintéticos de tamaño {group_size}.\")\n","\n","# --- PASO 3: Agregar Predicciones para cada Grupo ---\n","print(\"\\nAgregando predicciones para cada grupo...\")\n","all_group_recs = []\n","for group_id, user_ids in enumerate(groups):\n","    group_predictions = df_eval[df_eval['userID'].isin(user_ids)]\n","    item_scores_per_group = group_predictions.groupby('itemID').agg(\n","        avg_score=('score', 'mean'),\n","        min_score=('score', 'min'),\n","        max_score=('score', 'max'),\n","        group_label=('label', lambda x: 1 if x.sum() > 0 else 0)\n","    ).reset_index()\n","    item_scores_per_group['group_id'] = group_id\n","    all_group_recs.append(item_scores_per_group)\n","\n","df_group_eval = pd.concat(all_group_recs, ignore_index=True)\n","print(\"Agregación completada.\")\n","\n","# --- PASO 4: Evaluación de Estrategias con Todas las Métricas ---\n","strategies = {\n","    'Average': 'avg_score',\n","    'Least Misery': 'min_score',\n","    'Most Pleasure': 'max_score'\n","}\n","\n","group_results = []\n","K_values = [10]\n","\n","for strategy_name, score_column in strategies.items():\n","    print(f\"\\nEvaluando estrategia: {strategy_name}...\")\n","    df_strategy_eval = df_group_eval[['group_id', 'itemID', 'group_label']].copy()\n","    df_strategy_eval.rename(columns={'group_label': 'label'}, inplace=True)\n","    df_strategy_eval['score'] = df_group_eval[score_column]\n","\n","    grouped_strategy = df_strategy_eval.groupby('group_id')\n","\n","    for k in K_values:\n","        # Métricas existentes\n","        metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","        avg_precision = np.mean([m[0] for m in metrics])\n","        avg_recall = np.mean([m[1] for m in metrics])\n","        avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n","\n","        # Nuevas métricas\n","        avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","        avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n","\n","        group_results.append({\n","            'Strategy': strategy_name,\n","            'K': k,\n","            'Precision@K': avg_precision,\n","            'Recall@K': avg_recall,\n","            'nDCG@K': avg_ndcg,\n","            'Novelty@K': avg_novelty,\n","            'Diversity@K': avg_diversity\n","        })\n","\n","group_results_df = pd.DataFrame(group_results)\n","\n","print(\"\\n--- Resultados de Evaluación Grupal para SVD++ ---\")\n","print(group_results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"maf5rNBCmPMR","executionInfo":{"status":"ok","timestamp":1765000379086,"user_tz":180,"elapsed":240150,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"9862f304-55e4-40bf-c40d-3f263238274e"},"id":"maf5rNBCmPMR","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Convirtiendo predicciones de Surprise a DataFrame...\n","DataFrame de evaluación creado con éxito.\n","\n","Creando grupos sintéticos...\n","Se crearon 1000 grupos sintéticos de tamaño 4.\n","\n","Agregando predicciones para cada grupo...\n","Agregación completada.\n","\n","Evaluando estrategia: Average...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3131144893.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-3131144893.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-3131144893.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","/tmp/ipython-input-3131144893.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia: Least Misery...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3131144893.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-3131144893.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-3131144893.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","/tmp/ipython-input-3131144893.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["\n","Evaluando estrategia: Most Pleasure...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3131144893.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n","/tmp/ipython-input-3131144893.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-3131144893.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Resultados de Evaluación Grupal para SVD++ ---\n","        Strategy   K  Precision@K  Recall@K    nDCG@K  Novelty@K  Diversity@K\n","0        Average  10       0.9022  0.143456  0.965680  10.466366     0.839938\n","1   Least Misery  10       0.9007  0.143193  0.965407  10.487870     0.840269\n","2  Most Pleasure  10       0.9090  0.144599  0.967759  10.385792     0.839156\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3131144893.py:65: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}
{"cells":[{"cell_type":"markdown","id":"a5c5e162","metadata":{"id":"a5c5e162"},"source":["### Configuración Inicial"]},{"cell_type":"code","source":["!pip uninstall -y numpy\n","!pip install numpy==1.26"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"id":"eoht7K8UUvuL","outputId":"dfa544be-10b4-470c-bf37-bbcd856211b8","executionInfo":{"status":"ok","timestamp":1765025883457,"user_tz":180,"elapsed":18042,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"id":"eoht7K8UUvuL","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: numpy 1.26.0\n","Uninstalling numpy-1.26.0:\n","  Successfully uninstalled numpy-1.26.0\n","Collecting numpy==1.26\n","  Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n","Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n","Installing collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.0 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n","music21 9.9.1 requires numpy>=1.26.4, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"ad698803652f42478ccae6d233705344"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install scikit-surprise --no-build-isolation --no-deps\n","!pip install memory_profiler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8xY-LUmUzjr","outputId":"85fada5b-3ad2-4d28-cc29-fbf13e1fa06d","executionInfo":{"status":"ok","timestamp":1765025971097,"user_tz":180,"elapsed":87627,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"id":"x8xY-LUmUzjr","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-surprise\n","  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: scikit-surprise\n","  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2708544 sha256=7a63c02253e4d6d4929678087eb7c0361523a88961c4b23451ac061f4643c5a7\n","  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n","Successfully built scikit-surprise\n","Installing collected packages: scikit-surprise\n","Successfully installed scikit-surprise-1.1.4\n","Collecting memory_profiler\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory_profiler) (5.9.5)\n","Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Installing collected packages: memory_profiler\n","Successfully installed memory_profiler-0.61.0\n"]}]},{"cell_type":"markdown","id":"c3f95148","metadata":{"id":"c3f95148"},"source":["### Instalación de Librerías"]},{"cell_type":"code","execution_count":3,"id":"80bca851","metadata":{"id":"80bca851","executionInfo":{"status":"ok","timestamp":1765025975169,"user_tz":180,"elapsed":4057,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[],"source":["import time\n","import json\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import defaultdict, Counter\n","from memory_profiler import memory_usage\n","import itertools\n","import scipy.sparse as sparse\n","import random\n","import gdown\n","from surprise import SVDpp, Dataset, Reader, accuracy\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.metrics.pairwise import cosine_similarity\n","from surprise import SVD, Dataset, Reader"]},{"cell_type":"markdown","id":"e0ae5cb5","metadata":{"id":"e0ae5cb5"},"source":["### Importación de los Datos"]},{"cell_type":"code","source":["gdown.download(id='1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx', output='training_ratings.csv', quiet=False)\n","gdown.download(id='1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16', output='validation_ratings.csv', quiet=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"OaUSf9OapGSh","executionInfo":{"status":"ok","timestamp":1765025985605,"user_tz":180,"elapsed":10430,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"dde2ec6b-2c50-4c9a-f2ba-f602abae16e9"},"id":"OaUSf9OapGSh","execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx\n","From (redirected): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx&confirm=t&uuid=c48e1823-e1b7-40f9-8b85-9e46fe35df66\n","To: /content/training_ratings.csv\n","100%|██████████| 205M/205M [00:02<00:00, 68.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16\n","To: /content/validation_ratings.csv\n","100%|██████████| 64.4M/64.4M [00:01<00:00, 63.4MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'validation_ratings.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","execution_count":5,"id":"8dd256b7","metadata":{"id":"8dd256b7","executionInfo":{"status":"ok","timestamp":1765025991407,"user_tz":180,"elapsed":5799,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[],"source":["df_train = pd.read_csv('training_ratings.csv')\n","df_val = pd.read_csv('validation_ratings.csv')"]},{"cell_type":"code","source":["# dataset mechanics\n","gdown.download(id='1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO', output='mechanics.csv', quiet=False)\n","df_mechanics = pd.read_csv('mechanics.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD18bHhEpd7m","executionInfo":{"status":"ok","timestamp":1765025993213,"user_tz":180,"elapsed":1793,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"6c1a5e33-116e-4dc3-b415-e5dfff09596e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO\n","To: /content/mechanics.csv\n","100%|██████████| 7.05M/7.05M [00:00<00:00, 55.6MB/s]\n"]}],"id":"VD18bHhEpd7m"},{"cell_type":"markdown","id":"62baea42","metadata":{"id":"62baea42"},"source":["### Preprocesamiento de Datos"]},{"cell_type":"code","source":["df_mechanics = pd.read_csv('mechanics.csv')\n","# Usamos BGGId como índice para que la búsqueda sea rápida\n","df_mechanics.set_index('BGGId', inplace=True)\n","print(\"Datos de mecánicas cargados y listos.\")\n","\n","# --- Calcular la popularidad de los ítems ---\n","# Usamos el dataframe de entrenamiento COMPLETO (df_train) para obtener una\n","# medida de popularidad global y precisa.\n","item_popularity = df_train['item'].value_counts().to_dict()\n","total_interactions = len(df_train)\n","\n","# Convertimos las cuentas en probabilidades para el cálculo de novedad\n","item_popularity_prob = {item_id: count / total_interactions for item_id, count in item_popularity.items()}\n","print(f\"Popularidad calculada para {len(item_popularity)} ítems.\")"],"metadata":{"id":"j_TroMS362w5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765025993871,"user_tz":180,"elapsed":655,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"96b9a735-9f4b-4beb-c8c4-3a02875d32e1"},"id":"j_TroMS362w5","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Datos de mecánicas cargados y listos.\n","Popularidad calculada para 16748 ítems.\n"]}]},{"cell_type":"code","source":["print(f\"Tamaño original del training set: {len(df_train)}\")\n","\n","# se obtiene un sample debido a que hay muchos datos y se demora mucho\n","df_train_sample = df_train.sample(n=10000000, random_state=42)\n","print(f\"Tamaño del nuevo training set (muestra): {len(df_train_sample)}\")\n","\n","# se obtiene un sample debido a que hay muchos datos y se demora mucho\n","df_val_sample = df_val.sample(n=500000, random_state=42)\n","print(f\"Tamaño del nuevo validation set (muestra): {len(df_val_sample)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uT2QRQhMFTZ7","executionInfo":{"status":"ok","timestamp":1765025999347,"user_tz":180,"elapsed":5457,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"65a48b1e-907b-4b2e-c483-4d33d74152f5"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamaño original del training set: 10211218\n","Tamaño del nuevo training set (muestra): 10000000\n","Tamaño del nuevo validation set (muestra): 500000\n"]}],"id":"uT2QRQhMFTZ7"},{"cell_type":"code","source":["from sklearn.metrics import ndcg_score\n","\n","def novelty_at_k(group, k, popularity_prob):\n","    \"\"\"Calcula la Novedad@K para un solo usuario/grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk_items = group.head(k)['itemID']\n","\n","    novelty_scores = []\n","    for item_id in topk_items:\n","        # Si un ítem no está en el diccionario de popularidad, se le asigna una probabilidad muy baja\n","        prob = popularity_prob.get(item_id, 1e-6)\n","        novelty_scores.append(-np.log2(prob))\n","\n","    return np.mean(novelty_scores) if novelty_scores else 0.0\n","\n","def diversity_at_k(group, k, mechanics_df):\n","    \"\"\"Calcula la Diversidad@K (Intra-List Diversity) para un solo usuario/grupo.\"\"\"\n","    group = group.sort_values('score', ascending=False)\n","    topk_items = group.head(k)['itemID'].tolist()\n","\n","    # Nos aseguramos de que los ítems recomendados tengan datos de mecánicas\n","    topk_items = [item for item in topk_items if item in mechanics_df.index]\n","\n","    if len(topk_items) < 2:\n","        return 0.0\n","\n","    item_vectors = mechanics_df.loc[topk_items].values\n","\n","    # Calculamos la disimilitud del coseno (1 - similitud) para todos los pares de ítems\n","    dissimilarity_sum = 0\n","    num_pairs = 0\n","    for i in range(len(item_vectors)):\n","        for j in range(i + 1, len(item_vectors)):\n","            sim = cosine_similarity([item_vectors[i]], [item_vectors[j]])[0][0]\n","            dissimilarity_sum += (1 - sim)\n","            num_pairs += 1\n","\n","    return dissimilarity_sum / num_pairs if num_pairs > 0 else 0.0\n","def precision_recall_at_k(group, k):\n","    group = group.sort_values('score', ascending=False)\n","    topk = group.head(k)\n","    hits = topk['label'].sum()\n","    total_relevant = group['label'].sum()\n","    precision = hits / k if k > 0 else 0\n","    recall = hits / total_relevant if total_relevant > 0 else 0\n","    return precision, recall\n","\n","def ndcg_at_k(group, k):\n","    if group['label'].sum() == 0: return 0.0\n","    ranked_group = group.sort_values('score', ascending=False).head(k)\n","    if len(ranked_group) < 2: return 0.0\n","    true_relevance = np.asarray([ranked_group['label'].values])\n","    predicted_scores = np.asarray([ranked_group['score'].values])\n","    return ndcg_score(true_relevance, predicted_scores)"],"metadata":{"id":"fllurWHM68UF","executionInfo":{"status":"ok","timestamp":1765025999356,"user_tz":180,"elapsed":6,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"id":"fllurWHM68UF","execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"id":"ee022c0b","metadata":{"id":"ee022c0b","executionInfo":{"status":"ok","timestamp":1765026002902,"user_tz":180,"elapsed":3548,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}}},"outputs":[],"source":["df_train.drop_duplicates(inplace=True, subset=['user', 'item'])\n","df_val.drop_duplicates(inplace=True, subset=['user', 'item'])"]},{"cell_type":"code","source":["\n","\n","# ==============================================================================\n","# 1. GENERACIÓN DE GRUPOS (Paso movido al inicio)\n","# ==============================================================================\n","# Necesitamos saber quiénes son los grupos ANTES de entrenar para crear sus perfiles.\n","# Usamos df_val para definir usuarios válidos (igual que en tu lógica original)\n","\n","print(\"Generando grupos para el entrenamiento...\")\n","user_counts = df_val['user'].value_counts() # Nota: en tu csv de val la col es 'user'\n","valid_users = user_counts[user_counts >= 5].index.tolist() # Filtro un poco más laxo para tener más opciones\n","\n","np.random.seed(42)\n","num_groups = 1000\n","group_size = 4\n","\n","# Crear grupos sintéticos\n","# (Aseguramos que los usuarios existan también en train para poder crear perfil)\n","users_in_train = set(df_train['user'].unique())\n","valid_users = [u for u in valid_users if u in users_in_train]\n","\n","groups_list = [np.random.choice(valid_users, group_size, replace=False) for _ in range(num_groups)]\n","print(f\"Se crearon {len(groups_list)} grupos sintéticos de tamaño {group_size}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDYeHfvORSlp","executionInfo":{"status":"ok","timestamp":1765026077905,"user_tz":180,"elapsed":74701,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"a78be096-55eb-4903-c88f-4a5f33f0310f"},"id":"rDYeHfvORSlp","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Generando grupos para el entrenamiento...\n","Se crearon 1000 grupos sintéticos de tamaño 4.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"jPMl2_ziRUXT"},"id":"jPMl2_ziRUXT"},{"cell_type":"code","source":["\n","# 2. CREACIÓN DE PERFILES AGREGADOS (LAS 3 ESTRATEGIAS A LA VEZ)\n","# ==============================================================================\n","\n","def create_all_strategy_profiles(df_train, groups_list):\n","    all_profiles = []\n","\n","    # Pre-agrupamos para velocidad\n","    df_train_indexed = df_train.set_index('user')\n","\n","    print(\"Generando perfiles para Average, Least Misery y Most Pleasure...\")\n","\n","    for i, members in enumerate(groups_list):\n","        # Filtramos datos de los miembros\n","        relevant_data = df_train[df_train['user'].isin(members)]\n","        if relevant_data.empty: continue\n","\n","        # --- ESTRATEGIA 1: AVERAGE (Promedio) ---\n","        df_avg = relevant_data.groupby('item')['rating'].mean().reset_index()\n","        df_avg['user'] = f'G_{i}_avg' # ID único para esta estrategia\n","        all_profiles.append(df_avg)\n","\n","        # --- ESTRATEGIA 2: LEAST MISERY (Mínimo) ---\n","        df_min = relevant_data.groupby('item')['rating'].min().reset_index()\n","        df_min['user'] = f'G_{i}_min'\n","        all_profiles.append(df_min)\n","\n","        # --- ESTRATEGIA 3: MOST PLEASURE (Máximo) ---\n","        df_max = relevant_data.groupby('item')['rating'].max().reset_index()\n","        df_max['user'] = f'G_{i}_max'\n","        all_profiles.append(df_max)\n","\n","    return pd.concat(all_profiles, ignore_index=True)\n","\n","# Generamos los perfiles de las 3 estrategias\n","df_groups_train = create_all_strategy_profiles(df_train, groups_list)\n","\n","# Unimos TODO al dataset de entrenamiento\n","df_train_augmented = pd.concat([df_train[['user', 'item', 'rating']],\n","                                df_groups_train[['user', 'item', 'rating']]],\n","                               ignore_index=True)\n","\n","print(f\"Ratings originales: {len(df_train)}\")\n","print(f\"Ratings de grupos (3 estrategias): {len(df_groups_train)}\")\n","print(f\"Total para entrenar: {len(df_train_augmented)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBqjGxBJSOwN","executionInfo":{"status":"ok","timestamp":1765026403263,"user_tz":180,"elapsed":325376,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"de3e263b-0462-447a-d957-43a861c2f68c"},"id":"xBqjGxBJSOwN","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Generando perfiles para Average, Least Misery y Most Pleasure...\n","Ratings originales: 10200445\n","Ratings de grupos (3 estrategias): 666825\n","Total para entrenar: 10867270\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"gtcJcletRUTv"},"id":"gtcJcletRUTv"},{"cell_type":"code","source":["\n","# ==============================================================================\n","# 3. ENTRENAMIENTO DEL MODELO (Con datos aumentados)\n","# ==============================================================================\n","\n","def train_mf_model_augmented(df_augmented):\n","    print(\"\\nIniciando entrenamiento SVD con perfiles de grupo...\")\n","    start_time = time.time()\n","\n","    min_rating = df_augmented['rating'].min()\n","    max_rating = df_augmented['rating'].max()\n","    reader = Reader(rating_scale=(min_rating, max_rating))\n","\n","    data = Dataset.load_from_df(df_augmented[['user', 'item', 'rating']], reader)\n","    trainset = data.build_full_trainset()\n","\n","    algo = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42, verbose=True)\n","    algo.fit(trainset)\n","\n","    print(f\"Modelo entrenado en {time.time() - start_time:.2f} segundos.\")\n","    return algo\n","\n","# Entrenamos\n","mf_algo_group = train_mf_model_augmented(df_train_augmented)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBkB9atoSR10","executionInfo":{"status":"ok","timestamp":1765026530506,"user_tz":180,"elapsed":127232,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"f444bc1d-c520-463f-eb8c-5cc70544152e"},"id":"kBkB9atoSR10","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iniciando entrenamiento SVD con perfiles de grupo...\n","Processing epoch 0\n","Processing epoch 1\n","Processing epoch 2\n","Processing epoch 3\n","Processing epoch 4\n","Processing epoch 5\n","Processing epoch 6\n","Processing epoch 7\n","Processing epoch 8\n","Processing epoch 9\n","Processing epoch 10\n","Processing epoch 11\n","Processing epoch 12\n","Processing epoch 13\n","Processing epoch 14\n","Processing epoch 15\n","Processing epoch 16\n","Processing epoch 17\n","Processing epoch 18\n","Processing epoch 19\n","Modelo entrenado en 126.53 segundos.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"uSPhTQFRRUM9"},"id":"uSPhTQFRRUM9"},{"cell_type":"code","source":["# EVALUACIÓN Y RESULTADOS COMPARATIVOS\n","results_aggregated_models = []\n","K_values = [10]\n","\n","# Mapeo para iterar limpiamente\n","strategies_map = {\n","    'Average': '_avg',\n","    'Least Misery': '_min',\n","    'Most Pleasure': '_max'\n","}\n","\n","print(\"\\nIniciando evaluación comparativa...\")\n","\n","for strategy_name, suffix in strategies_map.items():\n","    print(f\"Evaluando estrategia: {strategy_name}...\")\n","    group_eval_rows = []\n","\n","    for i, members in enumerate(groups_list):\n","        group_id_model = f'G_{i}{suffix}' # Ej: G_0_avg\n","\n","        # Obtenemos la \"verdad\" (Ground Truth) del grupo en validación\n","        # NOTA: El ground truth es siempre el mismo (basado en ratings reales),\n","        # lo que cambia es la predicción del modelo según la estrategia aprendida.\n","        member_val_data = df_val[df_val['user'].isin(members)]\n","        if member_val_data.empty: continue\n","\n","        # Ground Truth: Asumimos Average de validación como la verdad \"real\" del disfrute grupal\n","        # (Esto es estándar para evaluar: ¿Le gustó al grupo realmente?)\n","        group_truth = member_val_data.groupby('item')['rating'].mean().reset_index()\n","        group_truth['label'] = (group_truth['rating'] >= 7).astype(int)\n","\n","        # PREDICCIÓN: Aquí usamos el usuario específico de la estrategia (Ej: G_0_min)\n","        try:\n","            # Predecimos usando el perfil aprendido para esta estrategia\n","            group_truth['score'] = group_truth['item'].apply(\n","                lambda x: mf_algo_group.predict(group_id_model, x).est\n","            )\n","        except:\n","            # Si por alguna razón el grupo no tuvo items en train para esa estrategia\n","            continue\n","\n","        group_truth['group_id'] = i # ID numérico simple para agrupar\n","        group_truth['itemID'] = group_truth['item']\n","\n","        group_eval_rows.append(group_truth[['group_id', 'itemID', 'score', 'label']])\n","\n","    # Unimos resultados de esta estrategia\n","    if not group_eval_rows:\n","        print(f\"Advertencia: No se generaron evaluaciones para {strategy_name}\")\n","        continue\n","\n","    df_results_strat = pd.concat(group_eval_rows, ignore_index=True)\n","    grouped_strat = df_results_strat.groupby('group_id')\n","\n","    # Calcular métricas para esta estrategia\n","    for k in K_values:\n","        avg_precision = np.mean([m[0] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","        avg_recall = np.mean([m[1] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","        avg_ndcg = grouped_strat.apply(lambda x: ndcg_at_k(x, k)).mean()\n","        avg_novelty = grouped_strat.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","        avg_diversity = grouped_strat.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n","\n","        results_aggregated_models.append({\n","            'Model': 'MF (Aggregated Models)',\n","            'Strategy': strategy_name, # Average, Least Misery, etc.\n","            'K': k,\n","            'Precision@K': avg_precision,\n","            'Recall@K': avg_recall,\n","            'nDCG@K': avg_ndcg,\n","            'Novelty@K': avg_novelty,\n","            'Diversity@K': avg_diversity\n","        })\n","\n","# Mostrar tabla final\n","final_results_df = pd.DataFrame(results_aggregated_models)\n","print(\"\\n--- Resultados Finales: Comparación de Estrategias (MF for Groups) ---\")\n","print(final_results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvnpJ05_SVm2","executionInfo":{"status":"ok","timestamp":1765026939584,"user_tz":180,"elapsed":409064,"user":{"displayName":"Mariela Zambrano","userId":"13626181033812741166"}},"outputId":"a6652bd1-8a80-442d-a55b-98cfc2180e81"},"id":"lvnpJ05_SVm2","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iniciando evaluación comparativa...\n","Evaluando estrategia: Average...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4185916519.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_precision = np.mean([m[0] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_recall = np.mean([m[1] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strat.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-4185916519.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strat.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","/tmp/ipython-input-4185916519.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strat.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["Evaluando estrategia: Least Misery...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4185916519.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_precision = np.mean([m[0] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_recall = np.mean([m[1] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strat.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-4185916519.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strat.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n","/tmp/ipython-input-4185916519.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strat.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["Evaluando estrategia: Most Pleasure...\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4185916519.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_precision = np.mean([m[0] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:58: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_recall = np.mean([m[1] for m in grouped_strat.apply(lambda x: precision_recall_at_k(x, k))])\n","/tmp/ipython-input-4185916519.py:59: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_ndcg = grouped_strat.apply(lambda x: ndcg_at_k(x, k)).mean()\n","/tmp/ipython-input-4185916519.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_novelty = grouped_strat.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Resultados Finales: Comparación de Estrategias (MF for Groups) ---\n","                    Model       Strategy   K  Precision@K  Recall@K    nDCG@K  \\\n","0  MF (Aggregated Models)        Average  10       0.8848  0.215542  0.961039   \n","1  MF (Aggregated Models)   Least Misery  10       0.8850  0.215641  0.958562   \n","2  MF (Aggregated Models)  Most Pleasure  10       0.8832  0.215285  0.958945   \n","\n","   Novelty@K  Diversity@K  \n","0  10.386788     0.830329  \n","1  10.476683     0.831822  \n","2  10.313648     0.830394  \n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-4185916519.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  avg_diversity = grouped_strat.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":5}
{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a5c5e162",
      "metadata": {
        "id": "a5c5e162"
      },
      "source": [
        "### Configuración Inicial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "eoht7K8UUvuL",
        "outputId": "afd7b430-21da-4ddb-f194-54b6ba8e1960"
      },
      "id": "eoht7K8UUvuL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.0\n",
            "Uninstalling numpy-1.26.0:\n",
            "  Successfully uninstalled numpy-1.26.0\n",
            "Collecting numpy==1.26\n",
            "  Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Using cached numpy-1.26.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.0 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.0 which is incompatible.\n",
            "music21 9.9.1 requires numpy>=1.26.4, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "eb40e87792c64899ab707f5242e4c66d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise --no-build-isolation --no-deps\n",
        "!pip install memory_profiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8xY-LUmUzjr",
        "outputId": "4e69123e-7732-47ba-bd7a-7372278cd35e"
      },
      "id": "x8xY-LUmUzjr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Using cached scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2708559 sha256=d7db1dc5aa9b3c7bd8859f156f388cedc6e64e5e2895f6d51834d4bbaeeb9a2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Collecting memory_profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from memory_profiler) (5.9.5)\n",
            "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Installing collected packages: memory_profiler\n",
            "Successfully installed memory_profiler-0.61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3f95148",
      "metadata": {
        "id": "c3f95148"
      },
      "source": [
        "### Instalación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80bca851",
      "metadata": {
        "id": "80bca851"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "from memory_profiler import memory_usage\n",
        "import itertools\n",
        "import scipy.sparse as sparse\n",
        "import random\n",
        "import gdown\n",
        "from surprise import SVDpp, Dataset, Reader, accuracy\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Dataset, Reader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ae5cb5",
      "metadata": {
        "id": "e0ae5cb5"
      },
      "source": [
        "### Importación de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdown.download(id='1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx', output='training_ratings.csv', quiet=False)\n",
        "gdown.download(id='1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16', output='validation_ratings.csv', quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "OaUSf9OapGSh",
        "outputId": "921b4128-513c-42cd-b78f-be4a5f9ed7e6"
      },
      "id": "OaUSf9OapGSh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx\n",
            "From (redirected): https://drive.google.com/uc?id=1eGDDR1wlvR99eoCZG2owChy2dhkPp4yx&confirm=t&uuid=d9255e43-8d7e-4abb-8fac-86b43f8b9f6d\n",
            "To: /content/training_ratings.csv\n",
            "100%|██████████| 205M/205M [00:01<00:00, 142MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1oHo9HLB6SzeqZs76FCkfQ1irSQepqp16\n",
            "To: /content/validation_ratings.csv\n",
            "100%|██████████| 64.4M/64.4M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'validation_ratings.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd256b7",
      "metadata": {
        "id": "8dd256b7"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('training_ratings.csv')\n",
        "df_val = pd.read_csv('validation_ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset mechanics\n",
        "gdown.download(id='1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO', output='mechanics.csv', quiet=False)\n",
        "df_mechanics = pd.read_csv('mechanics.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD18bHhEpd7m",
        "outputId": "0616b864-c28b-4d1b-b23e-a0ef636928e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cVGSLNVqxrAoKzeqxt_FfQ4Ggs9VvCDO\n",
            "To: /content/mechanics.csv\n",
            "100%|██████████| 7.05M/7.05M [00:00<00:00, 232MB/s]\n"
          ]
        }
      ],
      "id": "VD18bHhEpd7m"
    },
    {
      "cell_type": "markdown",
      "id": "62baea42",
      "metadata": {
        "id": "62baea42"
      },
      "source": [
        "### Preprocesamiento de Datos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_mechanics = pd.read_csv('mechanics.csv')\n",
        "# Usamos BGGId como índice para que la búsqueda sea rápida\n",
        "df_mechanics.set_index('BGGId', inplace=True)\n",
        "print(\"Datos de mecánicas cargados y listos.\")\n",
        "\n",
        "# --- Calcular la popularidad de los ítems ---\n",
        "# Usamos el dataframe de entrenamiento COMPLETO (df_train) para obtener una\n",
        "# medida de popularidad global y precisa.\n",
        "item_popularity = df_train['item'].value_counts().to_dict()\n",
        "total_interactions = len(df_train)\n",
        "\n",
        "# Convertimos las cuentas en probabilidades para el cálculo de novedad\n",
        "item_popularity_prob = {item_id: count / total_interactions for item_id, count in item_popularity.items()}\n",
        "print(f\"Popularidad calculada para {len(item_popularity)} ítems.\")"
      ],
      "metadata": {
        "id": "j_TroMS362w5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5942074a-6695-4698-bda3-6f1cf8c7a970"
      },
      "id": "j_TroMS362w5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de mecánicas cargados y listos.\n",
            "Popularidad calculada para 16748 ítems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def novelty_at_k(group, k, popularity_prob):\n",
        "    \"\"\"Calcula la Novedad@K para un solo usuario/grupo.\"\"\"\n",
        "    group = group.sort_values('score', ascending=False)\n",
        "    topk_items = group.head(k)['itemID']\n",
        "\n",
        "    novelty_scores = []\n",
        "    for item_id in topk_items:\n",
        "        # Si un ítem no está en el diccionario de popularidad, se le asigna una probabilidad muy baja\n",
        "        prob = popularity_prob.get(item_id, 1e-6)\n",
        "        novelty_scores.append(-np.log2(prob))\n",
        "\n",
        "    return np.mean(novelty_scores) if novelty_scores else 0.0\n",
        "\n",
        "def diversity_at_k(group, k, mechanics_df):\n",
        "    \"\"\"Calcula la Diversidad@K (Intra-List Diversity) para un solo usuario/grupo.\"\"\"\n",
        "    group = group.sort_values('score', ascending=False)\n",
        "    topk_items = group.head(k)['itemID'].tolist()\n",
        "\n",
        "    # Nos aseguramos de que los ítems recomendados tengan datos de mecánicas\n",
        "    topk_items = [item for item in topk_items if item in mechanics_df.index]\n",
        "\n",
        "    if len(topk_items) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    item_vectors = mechanics_df.loc[topk_items].values\n",
        "\n",
        "    # Calculamos la disimilitud del coseno (1 - similitud) para todos los pares de ítems\n",
        "    dissimilarity_sum = 0\n",
        "    num_pairs = 0\n",
        "    for i in range(len(item_vectors)):\n",
        "        for j in range(i + 1, len(item_vectors)):\n",
        "            sim = cosine_similarity([item_vectors[i]], [item_vectors[j]])[0][0]\n",
        "            dissimilarity_sum += (1 - sim)\n",
        "            num_pairs += 1\n",
        "\n",
        "    return dissimilarity_sum / num_pairs if num_pairs > 0 else 0.0\n",
        "\n",
        "def train_mf_model(df_train):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de Matrix Factorization (SVD de Surprise)\n",
        "    usando el mismo esquema de datos que ya tienes:\n",
        "    columnas: user, item, rating.\n",
        "    \"\"\"\n",
        "    min_rating = df_train['rating'].min()\n",
        "    max_rating = df_train['rating'].max()\n",
        "    reader = Reader(rating_scale=(min_rating, max_rating))\n",
        "\n",
        "    data = Dataset.load_from_df(df_train[['user', 'item', 'rating']], reader)\n",
        "    trainset = data.build_full_trainset()\n",
        "\n",
        "    algo = SVDpp(\n",
        "        n_factors=50,\n",
        "        n_epochs=20,\n",
        "        lr_all=0.005,\n",
        "        reg_all=0.02,\n",
        "        random_state=42\n",
        "    )\n",
        "    algo.fit(trainset)\n",
        "    return algo\n"
      ],
      "metadata": {
        "id": "fllurWHM68UF"
      },
      "id": "fllurWHM68UF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee022c0b",
      "metadata": {
        "id": "ee022c0b"
      },
      "outputs": [],
      "source": [
        "df_train.drop_duplicates(inplace=True, subset=['user', 'item'])\n",
        "df_val.drop_duplicates(inplace=True, subset=['user', 'item'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tamaño original del training set: {len(df_train)}\")\n",
        "\n",
        "# se obtiene un sample debido a que hay muchos datos y se demora mucho\n",
        "df_train_sample = df_train.sample(n=10000000, random_state=42)\n",
        "print(f\"Tamaño del nuevo training set (muestra): {len(df_train_sample)}\")\n",
        "\n",
        "# se obtiene un sample debido a que hay muchos datos y se demora mucho\n",
        "df_val_sample = df_val.sample(n=500000, random_state=42)\n",
        "print(f\"Tamaño del nuevo validation set (muestra): {len(df_val_sample)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT2QRQhMFTZ7",
        "outputId": "2ec22f61-c864-400e-9eae-18418fecfca9"
      },
      "id": "uT2QRQhMFTZ7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño original del training set: 10200445\n",
            "Tamaño del nuevo training set (muestra): 10000000\n",
            "Tamaño del nuevo validation set (muestra): 500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mf_algo = train_mf_model(df_train_sample)"
      ],
      "metadata": {
        "id": "HCECtpv0aSNO"
      },
      "id": "HCECtpv0aSNO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_eval_df_mf(df_val_sample, algo):\n",
        "    \"\"\"\n",
        "    Crea un DataFrame de evaluación con las mismas columnas que usas para Random,\n",
        "    pero usando como 'score' la predicción del modelo MF.\n",
        "    \"\"\"\n",
        "    df_eval_mf = df_val_sample.copy()\n",
        "    df_eval_mf = df_eval_mf.rename(columns={'user': 'userID', 'item': 'itemID'})\n",
        "\n",
        "    # Etiqueta de relevancia (igual que antes)\n",
        "    df_eval_mf['label'] = (df_eval_mf['rating'] >= 7).astype(int)\n",
        "\n",
        "    # Predicción MF para cada interacción usuario-item del conjunto de validación\n",
        "    df_eval_mf['score'] = df_eval_mf.apply(\n",
        "        lambda row: algo.predict(row['userID'], row['itemID']).est,\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    return df_eval_mf\n",
        "\n",
        "\n",
        "# Medir tiempo de ejecución\n",
        "start_time = time.time()\n",
        "df_eval_mf = build_eval_df_mf(df_val_sample, mf_algo)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Tiempo de ejecución: {elapsed_time:.2f} segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epNk4GNmBVct",
        "outputId": "530e47ad-b09d-4bb2-8363-168e3b565de2"
      },
      "id": "epNk4GNmBVct",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución: 146.34 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "\n",
        "def rmse_mae_mf(df_eval_mf):\n",
        "    y_true = df_eval_mf['rating'].values\n",
        "    y_pred = df_eval_mf['score'].values\n",
        "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    return rmse, mae\n",
        "\n",
        "rmse_mf, mae_mf = rmse_mae_mf(df_eval_mf)\n",
        "print(\"MF - RMSE:\", rmse_mf)\n",
        "print(\"MF - MAE:\", mae_mf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQptPHUXIuPi",
        "outputId": "a0ddc0b8-0fb2-45bb-ff69-27d0ba0c5ad2"
      },
      "id": "sQptPHUXIuPi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MF - RMSE: 1.2515531550251984\n",
            "MF - MAE: 0.9479160424083248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Funciones de métrica de ranking (puedes moverlas si ya las tienes en otra celda) ---\n",
        "def precision_recall_at_k(group, k):\n",
        "    group = group.sort_values('score', ascending=False)\n",
        "    topk = group.head(k)\n",
        "    hits = topk['label'].sum()\n",
        "    total_relevant = group['label'].sum()\n",
        "    precision = hits / k if k > 0 else 0\n",
        "    recall = hits / total_relevant if total_relevant > 0 else 0\n",
        "    return precision, recall\n",
        "\n",
        "def ndcg_at_k(group, k):\n",
        "    if group['label'].sum() == 0: return 0.0\n",
        "    ranked_group = group.sort_values('score', ascending=False).head(k)\n",
        "    if len(ranked_group) < 2: return 0.0\n",
        "    true_relevance = np.asarray([ranked_group['label'].values])\n",
        "    predicted_scores = np.asarray([ranked_group['score'].values])\n",
        "    return ndcg_score(true_relevance, predicted_scores)"
      ],
      "metadata": {
        "id": "kOiqq6zmhe_g"
      },
      "id": "kOiqq6zmhe_g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Individuales"
      ],
      "metadata": {
        "id": "jayILfodnCHf"
      },
      "id": "jayILfodnCHf"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "K_values = [10]\n",
        "individual_results_mf = []\n",
        "print(\"Calculando métricas de ranking individuales para MF...\")\n",
        "\n",
        "# El df_eval_mf ya tiene todo lo que necesitamos: userID, itemID, label, score\n",
        "grouped_users = df_eval_mf.groupby('userID')\n",
        "\n",
        "for k in K_values:\n",
        "    # Métricas de precisión y ranking\n",
        "    metrics = grouped_users.apply(lambda x: precision_recall_at_k(x, k))\n",
        "    avg_precision = np.mean([m[0] for m in metrics])\n",
        "    avg_recall = np.mean([m[1] for m in metrics])\n",
        "    avg_ndcg = grouped_users.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
        "\n",
        "    # Métricas de Novedad y Diversidad\n",
        "    avg_novelty = grouped_users.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n",
        "    avg_diversity = grouped_users.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n",
        "\n",
        "    individual_results_mf.append({\n",
        "        'K': k,\n",
        "        'Precision@K': avg_precision,\n",
        "        'Recall@K': avg_recall,\n",
        "        'nDCG@K': avg_ndcg,\n",
        "        'Novelty@K': avg_novelty,\n",
        "        'Diversity@K': avg_diversity\n",
        "    })\n",
        "\n",
        "individual_results_mf_df = pd.DataFrame(individual_results_mf)\n",
        "print(\"\\n--- Resultados de Evaluación Individual (MF) ---\")\n",
        "print(individual_results_mf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SXF00M2nGNX",
        "outputId": "31fb0149-bf3c-4c83-805f-07e03f1aa809"
      },
      "id": "2SXF00M2nGNX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando métricas de ranking individuales para MF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-335260646.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  metrics = grouped_users.apply(lambda x: precision_recall_at_k(x, k))\n",
            "/tmp/ipython-input-335260646.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_ndcg = grouped_users.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
            "/tmp/ipython-input-335260646.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_novelty = grouped_users.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados de Evaluación Individual (MF) ---\n",
            "    K  Precision@K  Recall@K    nDCG@K  Novelty@K  Diversity@K\n",
            "0  10     0.205777  0.867373  0.525121    10.9902     0.494416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-335260646.py:19: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_diversity = grouped_users.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grupales"
      ],
      "metadata": {
        "id": "6lpwVQaFnEe8"
      },
      "id": "6lpwVQaFnEe8"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "\n",
        "# Asegúrate de que df_eval está definido como en el paso anterior.\n",
        "# df_eval ya contiene las columnas: userID, itemID, rating, label, y score aleatorio.\n",
        "\n",
        "print(\"\\nCreando grupos sintéticos (MF)...\")\n",
        "user_counts = df_eval_mf['userID'].value_counts()\n",
        "valid_users = user_counts[user_counts >= 10].index.tolist()\n",
        "\n",
        "np.random.seed(42)\n",
        "num_groups = 1000\n",
        "group_size = 4\n",
        "if len(valid_users) < group_size * num_groups:\n",
        "    print(f\"Advertencia: No hay suficientes usuarios únicos ({len(valid_users)}) para crear {num_groups} grupos sin reemplazo. Se crearán menos grupos.\")\n",
        "    num_groups = len(valid_users) // group_size\n",
        "\n",
        "groups = [np.random.choice(valid_users, group_size, replace=False) for _ in range(num_groups)]\n",
        "print(f\"Se crearon {len(groups)} grupos sintéticos de tamaño {group_size}.\")\n",
        "\n",
        "\n",
        "print(\"\\nAgregando predicciones MF para cada grupo...\")\n",
        "all_group_recs = []\n",
        "for group_id, user_ids in enumerate(groups):\n",
        "    group_predictions = df_eval_mf[df_eval_mf['userID'].isin(user_ids)]\n",
        "    item_scores_per_group = group_predictions.groupby('itemID').agg(\n",
        "        avg_score=('score', 'mean'),\n",
        "        min_score=('score', 'min'),\n",
        "        max_score=('score', 'max'),\n",
        "        group_label=('label', lambda x: 1 if all(x == 1) else 0)\n",
        "    ).reset_index()\n",
        "    item_scores_per_group['group_id'] = group_id\n",
        "    all_group_recs.append(item_scores_per_group)\n",
        "\n",
        "df_group_eval_mf = pd.concat(all_group_recs, ignore_index=True)\n",
        "print(\"Agregación completada.\")\n",
        "\n",
        "\n",
        "# --- Evaluación de Estrategias con Todas las Métricas ---\n",
        "strategies = {\n",
        "    'Average': 'avg_score',\n",
        "    'Least Misery': 'min_score',\n",
        "    'Most Pleasure': 'max_score'\n",
        "}\n",
        "\n",
        "group_results_mf = []\n",
        "K_values = [10]\n",
        "\n",
        "for strategy_name, score_column in strategies.items():\n",
        "    print(f\"\\nEvaluando estrategia (MF): {strategy_name}...\")\n",
        "    df_strategy_eval = df_group_eval_mf[['group_id', 'itemID', 'group_label']].copy()\n",
        "    df_strategy_eval.rename(columns={'group_label': 'label'}, inplace=True)\n",
        "    df_strategy_eval['score'] = df_group_eval_mf[score_column]\n",
        "\n",
        "    grouped_strategy = df_strategy_eval.groupby('group_id')\n",
        "\n",
        "    for k in K_values:\n",
        "        metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n",
        "        avg_precision = np.mean([m[0] for m in metrics])\n",
        "        avg_recall = np.mean([m[1] for m in metrics])\n",
        "        avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
        "        avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n",
        "        avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n",
        "\n",
        "        group_results_mf.append({\n",
        "            'Model': 'MF',\n",
        "            'Strategy': strategy_name,\n",
        "            'K': k,\n",
        "            'Precision@K': avg_precision,\n",
        "            'Recall@K': avg_recall,\n",
        "            'nDCG@K': avg_ndcg,\n",
        "            'Novelty@K': avg_novelty,\n",
        "            'Diversity@K': avg_diversity\n",
        "        })\n",
        "\n",
        "group_results_mf_df = pd.DataFrame(group_results_mf)\n",
        "print(\"\\n--- Resultados de Evaluación Grupal para MF ---\")\n",
        "print(group_results_mf_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nHeuu_oyCcC",
        "outputId": "3f9fce7e-744a-4ce2-d4e9-65b05e016f4a"
      },
      "id": "0nHeuu_oyCcC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creando grupos sintéticos (MF)...\n",
            "Se crearon 1000 grupos sintéticos de tamaño 4.\n",
            "\n",
            "Agregando predicciones MF para cada grupo...\n",
            "Agregación completada.\n",
            "\n",
            "Evaluando estrategia (MF): Average...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7345840.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n",
            "/tmp/ipython-input-7345840.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
            "/tmp/ipython-input-7345840.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n",
            "/tmp/ipython-input-7345840.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluando estrategia (MF): Least Misery...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7345840.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n",
            "/tmp/ipython-input-7345840.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
            "/tmp/ipython-input-7345840.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n",
            "/tmp/ipython-input-7345840.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluando estrategia (MF): Most Pleasure...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7345840.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  metrics = grouped_strategy.apply(lambda x: precision_recall_at_k(x, k))\n",
            "/tmp/ipython-input-7345840.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_ndcg = grouped_strategy.apply(lambda x: ndcg_at_k(x, k)).mean()\n",
            "/tmp/ipython-input-7345840.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_novelty = grouped_strategy.apply(lambda x: novelty_at_k(x, k, item_popularity_prob)).mean()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados de Evaluación Grupal para MF ---\n",
            "  Model       Strategy   K  Precision@K  Recall@K    nDCG@K  Novelty@K  \\\n",
            "0    MF        Average  10       0.8958  0.257892  0.972665  10.631384   \n",
            "1    MF   Least Misery  10       0.8965  0.258081  0.972729  10.642940   \n",
            "2    MF  Most Pleasure  10       0.8907  0.256371  0.970726  10.619368   \n",
            "\n",
            "   Diversity@K  \n",
            "0     0.839455  \n",
            "1     0.839712  \n",
            "2     0.839604  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7345840.py:62: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  avg_diversity = grouped_strategy.apply(lambda x: diversity_at_k(x, k, df_mechanics)).mean()\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

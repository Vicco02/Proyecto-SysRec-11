# Proyecto Final: Recomendaci贸n Grupal de Juegos de Mesa
## IIC3633 - Sistemas Recomendadores (2025-2)

Este repositorio contiene la implementaci贸n, an谩lisis y evaluaci贸n de diferentes modelos de recomendaci贸n (Baselines, Factorizaci贸n Matricial y Deep Learning) aplicados a un contexto grupal utilizando el dataset de **BoardGameGeek**.

El proyecto explora estrategias de agregaci贸n de predicciones (*Average, Least Misery, Most Pleasure*) y compara arquitecturas de modelado (*Aggregated Predictions* vs. *Aggregated Models*).

---

###  Integrantes - Grupo 11

* **Vicente Correa** - vicente.correa@uc.cl
* **Alberto Maturana** - alberto.maturana@uc.cl
* **Mariela Zambrano** - mariela.zambrano@uc.cl

---

###  Estructura del Proyecto

El proyecto se divide en 7 notebooks principales (uno por modelo + an谩lisis de datos) y los informes de entrega.

#### 1. Preprocesamiento y An谩lisis
* `data_analysis.ipynb`: Contiene la carga del dataset crudo, el an谩lisis exploratorio (distribuciones, long-tail), el filtrado de usuarios/items (k-core) y la **separaci贸n de los conjuntos de datos** (Training, Validation, Testing).

#### 2. Modelos (Notebooks independientes)
* `MF.ipynb`: Implementaci贸n de Matrix Factorization con agregaci贸n de predicciones.
* `MF_for_groups.ipynb`: Implementaci贸n de la arquitectura **Aggregated Models** (perfiles grupales pre-entrenamiento).
* `SVD++.ipynb`: Implementaci贸n del algoritmo SVD++ (feedback impl铆cito).
* `DeepFM.ipynb`: Implementaci贸n del modelo h铆brido utilizando DeepCTR-Torch.
* `Random.ipynb`: Baseline aleatorio.
* `Most_Popular.ipynb`: Baseline de popularidad.

---

### 锔 Requisitos y Dependencias

El c贸digo est谩 dise帽ado para ejecutarse en **Google Colab**. Las librer铆as principales utilizadas son:
* `numpy==1.26` (Cr铆tico para compatibilidad con Surprise)
* `scikit-surprise` (Para modelos de factorizaci贸n)
* `deepctr-torch` (Para DeepFM)
* `gdown` (Para descarga autom谩tica de datos)

> **Nota:** Todas las instalaciones necesarias se encuentran en la primera celda de cada notebook.

---

###  Instrucciones de Ejecuci贸n

#### 1. Obtenci贸n de los Datos
No es necesario descargar manualmente el dataset. Todos los notebooks incluyen un bloque de c贸digo que utiliza `gdown` para descargar autom谩ticamente el archivo `.zip` con los datos procesados (train/val/test) directamente desde Google Drive al entorno de Colab.

#### 2. Ejecuci贸n de Modelos (MF, SVD++, Random, Most Popular, MF for Groups)
Estos notebooks requieren una versi贸n espec铆fica de Numpy para funcionar con la librer铆a Surprise:

1.  Abrir el notebook en Google Colab.
2.  Ejecutar la **primera celda** (instalaci贸n de librer铆as y `numpy==1.26`) y esperar.
3.  **REINICIAR LA SESIN (RUNTIME)**
4.  Ejecutar el resto de las celdas secuencialmente (`Run All` despu茅s del reinicio).

#### 3. Ejecuci贸n de DeepFM (`DeepFM.ipynb`)
Este notebook no requiere el reinicio por Numpy. Simplemente abra el archivo y ejecute todas las celdas en orden.

---

### 锔 Consideraciones de Tiempo y Hardware

* **Hardware:** Se recomienda utilizar el entorno est谩ndar de Colab. Para `DeepFM`, el uso de GPU (T4) acelerar谩 el entrenamiento, aunque no es estrictamente obligatorio.
* **Tiempo de Ejecuci贸n:** Tenga en cuenta que algunos modelos son computacionalmente costosos:
    * *Most Popular* y *MF* pueden tardar **aprox. 1 hora** en completar todas las evaluaciones y m茅tricas grupales.
    * Se recomienda no cerrar la pesta帽a del navegador durante la ejecuci贸n.

---

###  Referencias
El proyecto utiliza el dataset *Board Games Database* de BoardGameGeek (Kaggle): https://www.kaggle.com/datasets/threnjen/board-games-database-from-boardgamegeek. Para detalles sobre la metodolog铆a y resultados, referirse al informe final adjunto en la entrega.
